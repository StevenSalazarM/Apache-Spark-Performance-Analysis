1) Check negative time, atm only get_times.py from OverallTimeCache and LoadTimeNoCache got partially fixed. This must be included in all get_times.py files and for every date2-date1
2) Redo test m5_2xlarge 2 worker 4 cores, the load time cache was a lot higher of what expected, the web UI shows that there were some problems with worker 0, it wasnt able to use all his memory so it was requiring more time. Atm only one test was correct so we are using that value
3) Add more tests for m5_2xlarge
4) same as 2) but for 2_worker_8_cores with load_time_no_cache, atm just removed those two values and replaced with 2 correct values (check web UI)
5) try increasing the number of executors, you should obtain better values. For example with 2 VM-4 executors cache and no cache
6) from test_m5_2xlarge plot_overall.py it is possible to see that the difference of time between cache and no cache decrease by increasing the number of cores and worker, maybe try with more cores and more workers. I bet it comes better idk why, i didnt expect this kind of behaviour
7) fix negative values for python3 ./plot_stacked_chart.py 6 NoCache 2M on m4_xlarge... probably the problem is related to a long load time, since we are talking about few seconds more test were needed or a higher dataset was needed. The load time for 2 cores is around 2.4 seconds while jobs is 10 seconds and output is 2.9 seconds so that makes computing=10-2.4*3-2.9 which gives a negative value, a possible solution may be to consider stage0, stage2, stage4 as load stage but again, this is not the best way because Spark Web UI and Rest API do not show the time related to each single operation since all is performed by the optimizer. The problem is present almost in all cases in which the dataset is less than 2M.

